{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:55:10.259439100Z",
     "start_time": "2024-04-24T19:55:09.410902100Z"
    }
   },
   "id": "cc2bc956ed471086"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1713174288421, experiment_id='1', last_update_time=1713174288421, lifecycle_stage='active', name='arboles', tags={}>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establecer la URI de la base de datos SQLite\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'sqlite:///mlruns.db'\n",
    "\n",
    "# Configuración de MLflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"arboles\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:55:12.770501500Z",
     "start_time": "2024-04-24T19:55:12.672882200Z"
    }
   },
   "id": "eb8ada0cc133638c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluación Por Pos Sobre General"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8366cb651608b29"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbol de decision: 3293565.0887573967\n",
      "          y_test   y_pred_rf        dif\n",
      "893    1000000.0   1000000.0        0.0\n",
      "827    1200000.0   1200000.0        0.0\n",
      "149    8000000.0   6000000.0  2000000.0\n",
      "872    3000000.0   1200000.0  1800000.0\n",
      "1173  14000000.0  10000000.0  4000000.0\n",
      "...          ...         ...        ...\n",
      "692     150000.0    200000.0    50000.0\n",
      "2091   1500000.0    800000.0   700000.0\n",
      "1103   6000000.0   2500000.0  3500000.0\n",
      "1589   4000000.0   9500000.0  5500000.0\n",
      "605    5000000.0   3000000.0  2000000.0\n",
      "\n",
      "[676 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Usuario\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defensas 3308995.7264957265\n",
      "Delanteros 1264224.1379310344\n",
      "Medios 4033686.1604711376\n",
      "Porteros 2029032.2580645161\n"
     ]
    }
   ],
   "source": [
    "df_original = df.copy()\n",
    "# Crear y entrenar el modelo de árbol de decisión\n",
    "clf = DecisionTreeRegressor(criterion=\"absolute_error\", random_state=RANDOM_STATE)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predecir con el modelo entrenado\n",
    "y_pred_rf = clf.predict(X_test)\n",
    "\n",
    "# Calcular el error\n",
    "error = mean_absolute_error(y_test, y_pred_rf)\n",
    "print(\"Arbol de decision:\", error)\n",
    "\n",
    "# Crear DataFrame de predicciones vs. reales\n",
    "pred_vs_real = pd.DataFrame({'y_test': y_test, 'y_pred_rf': y_pred_rf, 'dif': abs(y_test-y_pred_rf)})\n",
    "posiciones = ['Left-Back', 'Centre-Back', 'Defensive Midfield',\n",
    "       'Centre-Forward','Second Striker','Central Midfield', 'Left Winger',\n",
    "       'Attacking Midfield', 'Right-Back','Right Winger',\n",
    "       'Left Midfield', 'Goalkeeper']\n",
    "# Mostrar el DataFrame\n",
    "print(pred_vs_real)\n",
    "\n",
    "# Iniciar una nueva run de MLflow\n",
    "with mlflow.start_run(run_name=\"COMPORTAMIENTO POSICIONES EN MODELO COMPLETO\") as run:\n",
    "    # Registrar los hiperparámetros\n",
    "    mlflow.log_param(\"criterion\", \"mae\")\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    \n",
    "    # Registrar la métrica de error\n",
    "    mlflow.log_metric(\"mean_absolute_error\", error)\n",
    "    \n",
    "    # Guardar el modelo\n",
    "    mlflow.sklearn.log_model(clf, \"decision_tree_model\")\n",
    "    \n",
    "    # Guardar el DataFrame como un artefacto\n",
    "    pred_vs_real.to_csv(\"pred_vs_real.csv\", index=False)\n",
    "    mlflow.log_artifact(\"pred_vs_real.csv\")\n",
    "    \n",
    "    # Calcular medias por grupos de posiciones\n",
    "    li = []\n",
    "    for p in posiciones:\n",
    "        solo_posicion = df_original.loc[pred_vs_real.index][df_original.loc[pred_vs_real.index, 'position_' + p] == 1]\n",
    "        mean_dif = np.mean(pred_vs_real.loc[solo_posicion.index]['dif'])\n",
    "        li.append(mean_dif)\n",
    "\n",
    "    mean_defenders = np.mean(li[0:3])\n",
    "    mean_strikers = np.mean(li[3:5])\n",
    "    mean_midfielders = np.mean(li[5:11])\n",
    "    mean_goalkeepers = li[11]\n",
    "\n",
    "    print('Defensas', mean_defenders)\n",
    "    print('Delanteros', mean_strikers)\n",
    "    print('Medios', mean_midfielders)\n",
    "    print('Porteros', mean_goalkeepers)\n",
    "\n",
    "    # Guardar las métricas específicas en MLflow\n",
    "    mlflow.log_metric(\"mean_error_defenders\", mean_defenders)\n",
    "    mlflow.log_metric(\"mean_error_strikers\", mean_strikers)\n",
    "    mlflow.log_metric(\"mean_error_midfielders\", mean_midfielders)\n",
    "    mlflow.log_metric(\"mean_error_goalkeepers\", mean_goalkeepers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T23:02:34.031062700Z",
     "start_time": "2024-04-16T23:02:29.984845800Z"
    }
   },
   "id": "d7fbbd56d7ed6483"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Con Hiperparámetros"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "251d46a37b71f6d1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Datos_la_liga_preparados_entrenamiento.parquet guardado en: ../Downloads\\Datos_la_liga_preparados_entrenamiento.parquet\n",
      "Árbol de decisión - Validación: 3325382.003395586\n",
      "Árbol de decisión - Prueba: 3076823.84341637\n",
      "R^2 ajustado - Validación: 0.6974377642330392\n",
      "R^2 ajustado - Prueba: 0.6403587863414837\n",
      "Predicciones vs. reales - Validación:\n",
      "           y_val  y_pred_val     dif_val\n",
      "1100    200000.0    300000.0    100000.0\n",
      "1101  30000000.0  25000000.0   5000000.0\n",
      "1102  30000000.0  28000000.0   2000000.0\n",
      "1103   6000000.0   3200000.0   2800000.0\n",
      "1104  40000000.0  24750000.0  15250000.0\n",
      "...          ...         ...         ...\n",
      "1684   1000000.0    300000.0    700000.0\n",
      "1685   1000000.0    300000.0    700000.0\n",
      "1686    800000.0    800000.0         0.0\n",
      "1687    500000.0    300000.0    200000.0\n",
      "1688    500000.0   1000000.0    500000.0\n",
      "\n",
      "[589 rows x 3 columns]\n",
      "Predicciones vs. reales - Prueba:\n",
      "          y_test  y_pred_test    dif_test\n",
      "1689  25000000.0   32000000.0   7000000.0\n",
      "1690  25000000.0   25000000.0         0.0\n",
      "1691  30000000.0   48000000.0  18000000.0\n",
      "1692    300000.0     300000.0         0.0\n",
      "1693  14000000.0   40000000.0  26000000.0\n",
      "...          ...          ...         ...\n",
      "2246    500000.0     800000.0    300000.0\n",
      "2247    800000.0     800000.0         0.0\n",
      "2248    400000.0     300000.0    100000.0\n",
      "2249    400000.0     300000.0    100000.0\n",
      "2250    900000.0    2000000.0   1100000.0\n",
      "\n",
      "[562 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import preprocesamiento_datos\n",
    "RANDOM_STATE = 83\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = preprocesamiento_datos.preprocesamiento(True,[], False)\n",
    "clf = DecisionTreeRegressor(criterion=\"absolute_error\", max_depth=30, max_features=None, max_leaf_nodes=80, min_samples_leaf=5, min_samples_split=12, splitter=\"random\", random_state=RANDOM_STATE)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predecir con el modelo entrenado en el conjunto de validación\n",
    "y_pred_val = clf.predict(X_val)\n",
    "\n",
    "# Predecir con el modelo entrenado en el conjunto de prueba\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "# Calcular el error en el conjunto de validación\n",
    "error_val = mean_absolute_error(y_val, y_pred_val)\n",
    "print(\"Árbol de decisión - Validación:\", error_val)\n",
    "\n",
    "# Calcular el error en el conjunto de prueba\n",
    "error_test = mean_absolute_error(y_test, y_pred_test)\n",
    "print(\"Árbol de decisión - Prueba:\", error_test)\n",
    "\n",
    "# Crear DataFrame de predicciones vs. reales para el conjunto de validación\n",
    "pred_vs_real_val = pd.DataFrame({'y_val': y_val, 'y_pred_val': y_pred_val, 'dif_val': abs(y_val - y_pred_val)})\n",
    "\n",
    "# Crear DataFrame de predicciones vs. reales para el conjunto de prueba\n",
    "pred_vs_real_test = pd.DataFrame({'y_test': y_test, 'y_pred_test': y_pred_test, 'dif_test': abs(y_test - y_pred_test)})\n",
    "\n",
    "# Mostrar los DataFrames\n",
    "print(\"Predicciones vs. reales - Validación:\")\n",
    "print(pred_vs_real_val)\n",
    "\n",
    "print(\"Predicciones vs. reales - Prueba:\")\n",
    "print(pred_vs_real_test)\n",
    "\n",
    "# Iniciar una nueva run de MLflow\n",
    "with mlflow.start_run(run_name=\"FINAL MODEL TREE\") as run:\n",
    "    mlflow.log_param(\"criterion\", \"mae\")\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"max_depth\", 30)\n",
    "    mlflow.log_param(\"max_features\", None)\n",
    "    mlflow.log_param(\"max_leaf_nodes\", 80)\n",
    "    mlflow.log_param(\"min_samples_leaf\", 5)\n",
    "    mlflow.log_param(\"min_samples_split\", 12)\n",
    "    mlflow.log_param(\"splitter\", \"random\")\n",
    "    # Registrar la métrica de error en el conjunto de validación\n",
    "    mlflow.log_metric(\"mean_absolute_error_val\", error_val)\n",
    "    # Registrar la métrica de error en el conjunto de prueba\n",
    "    mlflow.log_metric(\"mean_absolute_error_test\", error_test)\n",
    "    # Guardar el modelo\n",
    "    mlflow.sklearn.log_model(clf, \"decision_tree_model\")\n",
    "    \n",
    "    # Guardar los DataFrames como un artefacto\n",
    "    pred_vs_real_val.to_csv(\"pred_vs_real_val.csv\", index=False)\n",
    "    mlflow.log_artifact(\"pred_vs_real_val.csv\")\n",
    "    \n",
    "    pred_vs_real_test.to_csv(\"pred_vs_real_test.csv\", index=False)\n",
    "    mlflow.log_artifact(\"pred_vs_real_test.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:55:26.710598600Z",
     "start_time": "2024-04-24T19:55:20.081897300Z"
    }
   },
   "id": "1c248f7818250dc7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sin hiperparámetros"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ce124ae4b09bd37"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Datos_la_liga_preparados_entrenamiento.parquet guardado en: ../Downloads\\Datos_la_liga_preparados_entrenamiento.parquet\n",
      "Árbol de decisión - Validación: 3664983.0220713075\n",
      "Árbol de decisión - Prueba: 3806628.1138790036\n",
      "Predicciones vs. reales - Validación:\n",
      "           y_val  y_pred_val     dif_val\n",
      "1100    200000.0    600000.0    400000.0\n",
      "1101  30000000.0  25000000.0   5000000.0\n",
      "1102  30000000.0  25000000.0   5000000.0\n",
      "1103   6000000.0  20000000.0  14000000.0\n",
      "1104  40000000.0  28000000.0  12000000.0\n",
      "...          ...         ...         ...\n",
      "1684   1000000.0   5000000.0   4000000.0\n",
      "1685   1000000.0    150000.0    850000.0\n",
      "1686    800000.0    400000.0    400000.0\n",
      "1687    500000.0    600000.0    100000.0\n",
      "1688    500000.0    600000.0    100000.0\n",
      "\n",
      "[589 rows x 3 columns]\n",
      "Predicciones vs. reales - Prueba:\n",
      "          y_test  y_pred_test    dif_test\n",
      "1689  25000000.0   32000000.0   7000000.0\n",
      "1690  25000000.0   24000000.0   1000000.0\n",
      "1691  30000000.0   40000000.0  10000000.0\n",
      "1692    300000.0     300000.0         0.0\n",
      "1693  14000000.0   18000000.0   4000000.0\n",
      "...          ...          ...         ...\n",
      "2246    500000.0     800000.0    300000.0\n",
      "2247    800000.0    1000000.0    200000.0\n",
      "2248    400000.0     300000.0    100000.0\n",
      "2249    400000.0    1000000.0    600000.0\n",
      "2250    900000.0    1200000.0    300000.0\n",
      "\n",
      "[562 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Usuario\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import preprocesamiento_datos\n",
    "RANDOM_STATE = 83\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = preprocesamiento_datos.preprocesamiento(True,[], False)\n",
    "clf = DecisionTreeRegressor(criterion=\"absolute_error\", random_state=RANDOM_STATE)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predecir con el modelo entrenado en el conjunto de validación\n",
    "y_pred_val = clf.predict(X_val)\n",
    "\n",
    "# Predecir con el modelo entrenado en el conjunto de prueba\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "# Calcular el error en el conjunto de validación\n",
    "error_val = mean_absolute_error(y_val, y_pred_val)\n",
    "print(\"Árbol de decisión - Validación:\", error_val)\n",
    "\n",
    "# Calcular el error en el conjunto de prueba\n",
    "error_test = mean_absolute_error(y_test, y_pred_test)\n",
    "print(\"Árbol de decisión - Prueba:\", error_test)\n",
    "\n",
    "# Crear DataFrame de predicciones vs. reales para el conjunto de validación\n",
    "pred_vs_real_val = pd.DataFrame({'y_val': y_val, 'y_pred_val': y_pred_val, 'dif_val': abs(y_val - y_pred_val)})\n",
    "\n",
    "# Crear DataFrame de predicciones vs. reales para el conjunto de prueba\n",
    "pred_vs_real_test = pd.DataFrame({'y_test': y_test, 'y_pred_test': y_pred_test, 'dif_test': abs(y_test - y_pred_test)})\n",
    "\n",
    "# Mostrar los DataFrames\n",
    "print(\"Predicciones vs. reales - Validación:\")\n",
    "print(pred_vs_real_val)\n",
    "\n",
    "print(\"Predicciones vs. reales - Prueba:\")\n",
    "print(pred_vs_real_test)\n",
    "\n",
    "# Iniciar una nueva run de MLflow\n",
    "with mlflow.start_run(run_name=\"MODEL Sin HiperParámetros\") as run:\n",
    "    mlflow.log_param(\"criterion\", \"mae\")\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"max_depth\", 30)\n",
    "    mlflow.log_param(\"max_features\", None)\n",
    "    mlflow.log_param(\"max_leaf_nodes\", 80)\n",
    "    mlflow.log_param(\"min_samples_leaf\", 5)\n",
    "    mlflow.log_param(\"min_samples_split\", 12)\n",
    "    mlflow.log_param(\"splitter\", \"random\")\n",
    "    # Registrar la métrica de error en el conjunto de validación\n",
    "    mlflow.log_metric(\"mean_absolute_error_val\", error_val)\n",
    "    # Registrar la métrica de error en el conjunto de prueba\n",
    "    mlflow.log_metric(\"mean_absolute_error_test\", error_test)\n",
    "    # Guardar el modelo\n",
    "    mlflow.sklearn.log_model(clf, \"decision_tree_model\")\n",
    "    \n",
    "    # Guardar los DataFrames como un artefacto\n",
    "    pred_vs_real_val.to_csv(\"pred_vs_real_val.csv\", index=False)\n",
    "    mlflow.log_artifact(\"pred_vs_real_val.csv\")\n",
    "    \n",
    "    pred_vs_real_test.to_csv(\"pred_vs_real_test.csv\", index=False)\n",
    "    mlflow.log_artifact(\"pred_vs_real_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:56:49.128909900Z",
     "start_time": "2024-04-24T19:56:45.233191900Z"
    }
   },
   "id": "94aea7f99622351e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "305289f9e2b6f82c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
