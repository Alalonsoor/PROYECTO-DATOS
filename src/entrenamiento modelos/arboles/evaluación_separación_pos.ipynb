{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_validate\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:21:55.418121800Z",
     "start_time": "2024-04-16T22:21:55.411588100Z"
    }
   },
   "id": "89b4388de74e2613"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Descarga de Archivos desde Google Drive sin Autenticación\n",
    "\n",
    "Este script permite descargar archivos específicos desde Google Drive directamente a una ubicación local,\n",
    "utilizando el ID de Google Drive del archivo (el archivo debe ser accesible para cualquier persona que tenga la URL).\n",
    "\n",
    "El script procesa un archivo de texto ('archivos_info.txt') que contiene las IDs de Google Drive de los archivos,\n",
    "los nombres con los que se desean guardar localmente, y las rutas locales de almacenamiento, todo separado por comas.\n",
    "\n",
    "Formato esperado de 'archivos_info.txt':\n",
    "ID_de_Google_Drive,Nombre_Archivo_Local,Ruta_Local\n",
    "\n",
    "Ejemplo:\n",
    "1hGvKmNAkK...,mi_archivo.txt,./descargas\n",
    "\n",
    "Requisitos:\n",
    "- Módulo 'requests' instalado en el entorno Python donde se ejecute este script.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "def descargar_archivo_directo(id_archivo, directorio_destino, archivo_destino):\n",
    "    \"\"\"\n",
    "    Descarga un archivo directamente desde Google Drive y lo guarda localmente.\n",
    "\n",
    "    Parámetros:\n",
    "    - id_archivo (str): ID del archivo en Google Drive.\n",
    "    - directorio_destino (str): Ruta del directorio local donde se guardará el archivo.\n",
    "    - archivo_destino (str): Nombre deseado para el archivo en local\n",
    "\n",
    "    Devuelve:\n",
    "    - archivo_destino (str): Nombre del archivo guardado.\n",
    "    - ruta_completa (str): Ruta completa del archivo guardado.\n",
    "    \"\"\"\n",
    "    # Construye la URL de descarga directa utilizando el ID del archivo\n",
    "    url = f\"https://drive.google.com/uc?export=download&id={id_archivo}\"\n",
    "\n",
    "    # Realiza la petición HTTP GET para descargar el archivo\n",
    "    respuesta = requests.get(url, allow_redirects=True)\n",
    "\n",
    "    # Comprueba que el directorio destino existe, si no, lo crea\n",
    "    os.makedirs(directorio_destino, exist_ok=True)\n",
    "\n",
    "    # Construye la ruta completa donde se guardará el archivo en local\n",
    "    ruta_completa = os.path.join(directorio_destino, archivo_destino)\n",
    "\n",
    "    # Guarda el contenido del archivo descargado en local\n",
    "    with open(ruta_completa, 'wb') as archivo:\n",
    "        archivo.write(respuesta.content)\n",
    "\n",
    "\n",
    "    return archivo_destino, ruta_completa\n",
    "\n",
    "\n",
    "def procesar_archivo_info(ruta_archivo_info):\n",
    "    \"\"\"\n",
    "    Procesa un archivo de texto que contiene información sobre los archivos a descargar.\n",
    "\n",
    "    Parámetros:\n",
    "    - ruta_archivo_info (str): Ruta del archivo de texto que contiene los IDs de Google Drive,\n",
    "                               los nombres de los archivos locales y las rutas locales.\n",
    "\n",
    "    Devuelve:\n",
    "    - Una lista de tuplas con el ID de Google Drive, el nombre local del archivo, y la ruta local.\n",
    "    \"\"\"\n",
    "    archivos_info = []\n",
    "    with open(ruta_archivo_info, 'r') as archivo:\n",
    "        for linea in archivo:\n",
    "            id_archivo, nombre_archivo, directorio_destino = linea.strip().split(',')\n",
    "            archivos_info.append((id_archivo, nombre_archivo, directorio_destino))\n",
    "    return archivos_info\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T23:10:05.048502600Z",
     "start_time": "2024-04-16T23:10:05.038978200Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo datos_preparados_solo_entr_pos.parquet guardado en: ../Downloads\\datos_preparados_solo_entr_pos.parquet\n"
     ]
    }
   ],
   "source": [
    "# Ruta al archivo que contiene la información de los archivos a descargar\n",
    "ruta_archivo_info = \"info_archivos_GDrive_solo_entr_pos.txt\"\n",
    "\n",
    "# Obtenemos la lista con la info de los archivos del fichero\n",
    "archivos_a_descargar = procesar_archivo_info(ruta_archivo_info)\n",
    "\n",
    "# Descargamos cada archivo de la lista\n",
    "for id_archivo, nombre_archivo, directorio_destino in archivos_a_descargar:\n",
    "    nombre_archivo_descargado, ruta_archivo_guardado = descargar_archivo_directo(id_archivo, directorio_destino, nombre_archivo)\n",
    "    print(f\"Archivo {nombre_archivo_descargado} guardado en: {ruta_archivo_guardado}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T23:10:08.133429300Z",
     "start_time": "2024-04-16T23:10:06.355869Z"
    }
   },
   "id": "7e9a51f13b3f3f3b"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mArrowInvalid\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_parquet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mruta_archivo_guardado\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpyarrow\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m df\u001B[38;5;241m.\u001B[39mdescribe()\n",
      "File \u001B[1;32m~\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001B[0m, in \u001B[0;36mread_parquet\u001B[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001B[0m\n\u001B[0;32m    664\u001B[0m     use_nullable_dtypes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    665\u001B[0m check_dtype_backend(dtype_backend)\n\u001B[1;32m--> 667\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    673\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    675\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\pandas\\io\\parquet.py:274\u001B[0m, in \u001B[0;36mPyArrowImpl.read\u001B[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001B[0m\n\u001B[0;32m    267\u001B[0m path_or_handle, handles, filesystem \u001B[38;5;241m=\u001B[39m _get_path_or_handle(\n\u001B[0;32m    268\u001B[0m     path,\n\u001B[0;32m    269\u001B[0m     filesystem,\n\u001B[0;32m    270\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[0;32m    271\u001B[0m     mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    272\u001B[0m )\n\u001B[0;32m    273\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 274\u001B[0m     pa_table \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparquet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_handle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    281\u001B[0m     result \u001B[38;5;241m=\u001B[39m pa_table\u001B[38;5;241m.\u001B[39mto_pandas(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mto_pandas_kwargs)\n\u001B[0;32m    283\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m manager \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1776\u001B[0m, in \u001B[0;36mread_table\u001B[1;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001B[0m\n\u001B[0;32m   1770\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1771\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPassing \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muse_legacy_dataset\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is deprecated as of pyarrow 15.0.0 \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1772\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand will be removed in a future version.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1773\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m   1775\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1776\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43mParquetDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1777\u001B[0m \u001B[43m        \u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1778\u001B[0m \u001B[43m        \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1779\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1780\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartitioning\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartitioning\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1781\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmemory_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1782\u001B[0m \u001B[43m        \u001B[49m\u001B[43mread_dictionary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mread_dictionary\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1783\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbuffer_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1784\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1785\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_prefixes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_prefixes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1786\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpre_buffer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1787\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoerce_int96_timestamp_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcoerce_int96_timestamp_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1788\u001B[0m \u001B[43m        \u001B[49m\u001B[43mthrift_string_size_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthrift_string_size_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1789\u001B[0m \u001B[43m        \u001B[49m\u001B[43mthrift_container_size_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthrift_container_size_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1790\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpage_checksum_verification\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpage_checksum_verification\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1791\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1792\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m   1793\u001B[0m     \u001B[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001B[39;00m\n\u001B[0;32m   1794\u001B[0m     \u001B[38;5;66;03m# module is not available\u001B[39;00m\n\u001B[0;32m   1795\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m filters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1343\u001B[0m, in \u001B[0;36mParquetDataset.__init__\u001B[1;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, use_legacy_dataset)\u001B[0m\n\u001B[0;32m   1339\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m single_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1340\u001B[0m     fragment \u001B[38;5;241m=\u001B[39m parquet_format\u001B[38;5;241m.\u001B[39mmake_fragment(single_file, filesystem)\n\u001B[0;32m   1342\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset \u001B[38;5;241m=\u001B[39m ds\u001B[38;5;241m.\u001B[39mFileSystemDataset(\n\u001B[1;32m-> 1343\u001B[0m         [fragment], schema\u001B[38;5;241m=\u001B[39mschema \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mfragment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mphysical_schema\u001B[49m,\n\u001B[0;32m   1344\u001B[0m         \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39mparquet_format,\n\u001B[0;32m   1345\u001B[0m         filesystem\u001B[38;5;241m=\u001B[39mfragment\u001B[38;5;241m.\u001B[39mfilesystem\n\u001B[0;32m   1346\u001B[0m     )\n\u001B[0;32m   1347\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   1349\u001B[0m \u001B[38;5;66;03m# check partitioning to enable dictionary encoding\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\pyarrow\\_dataset.pyx:1367\u001B[0m, in \u001B[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\pyarrow\\error.pxi:154\u001B[0m, in \u001B[0;36mpyarrow.lib.pyarrow_internal_check_status\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\pyarrow\\error.pxi:91\u001B[0m, in \u001B[0;36mpyarrow.lib.check_status\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mArrowInvalid\u001B[0m: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(ruta_archivo_guardado, engine = \"pyarrow\")\n",
    "\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T23:10:11.276568300Z",
     "start_time": "2024-04-16T23:10:10.260450700Z"
    }
   },
   "id": "ff78da7dcce3743f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "Y = df.iloc[:, -1]\n",
    "\n",
    "# Partición de datos\n",
    "RANDOM_STATE = 83\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=RANDOM_STATE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:24:36.545088500Z",
     "start_time": "2024-04-16T22:24:36.523439600Z"
    }
   },
   "id": "bfc12f6de11c6585"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1713174288421, experiment_id='1', last_update_time=1713174288421, lifecycle_stage='active', name='arboles', tags={}>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establecer la URI de la base de datos SQLite\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'sqlite:///mlruns.db'\n",
    "\n",
    "# Configuración de MLflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"arboles\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:24:37.141838200Z",
     "start_time": "2024-04-16T22:24:37.103479600Z"
    }
   },
   "id": "f645dcae45d615f9"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:24:37.701786600Z",
     "start_time": "2024-04-16T22:24:37.674215100Z"
    }
   },
   "id": "9fa3be7f648ecbd7"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Usuario\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "C:\\Users\\Usuario\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Usuario\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "C:\\Users\\Usuario\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Usuario\\Documents\\Alvaro\\Carrera\\2-Segundo\\Primer cuatrimetre\\Fundamentos de la Inteligencia Artificial\\PycharmProjects\\proyecto\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Mapeo de posiciones a dos grupos solamente: Porteros y Otros\n",
    "def map_position_to_group(position):\n",
    "    if position in ['Centre-Back', 'Left-Back', 'Right-Back']:\n",
    "        return 'Defensas'\n",
    "    elif position == 'Goalkeeper':\n",
    "        return 'Porteros'\n",
    "    elif position in ['Centre-Forward', 'Second Striker']:\n",
    "        return 'Delanteros'\n",
    "    else:\n",
    "        return 'Medios'\n",
    "\n",
    "# Crear una nueva columna 'Pos_Group' para grupos de posiciones\n",
    "df['Pos_Group'] = df['position'].apply(map_position_to_group)\n",
    "\n",
    "# Eliminar la columna 'position' ahora que tenemos 'Pos_Group'\n",
    "df.drop(columns=['position'], inplace=True)\n",
    "\n",
    "# Separar por grupos de posiciones y entrenar un modelo para cada uno\n",
    "for pos_group in ['Porteros', 'Defensas', 'Medios', 'Delanteros']:  # Solo usamos los grupos definidos\n",
    "    # Crear un DataFrame para el grupo de posiciones actual\n",
    "    df_group = df[df['Pos_Group'] == pos_group].copy()\n",
    "\n",
    "    # Eliminar la columna 'Pos_Group' del DataFrame actual\n",
    "    df_group.drop(columns=['Pos_Group'], inplace=True)\n",
    "\n",
    "    X = df_group.iloc[:, :-1]\n",
    "    Y = df_group.iloc[:, -1]\n",
    "\n",
    "    # Partición de datos\n",
    "    RANDOM_STATE = 83\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Crear el estimador\n",
    "    clf = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "    # Realizar validación cruzada\n",
    "    cv_scores = cross_validate(clf, X_train, y_train, scoring='neg_mean_absolute_error', cv=10, n_jobs=-1)\n",
    "\n",
    "    # Entrenar el modelo final\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir con el modelo entrenado\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calcular el error en el conjunto de prueba\n",
    "    test_error = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Iniciar una nueva run de MLflow\n",
    "    with mlflow.start_run(run_name=f\"prueba_{pos_group}\"):\n",
    "        # Registrar los hiperparámetros\n",
    "        mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "\n",
    "        # Registrar el error en el conjunto de prueba\n",
    "        mlflow.log_metric(f\"test_error_{pos_group}\", test_error)\n",
    "\n",
    "        # Guardar el modelo entrenado\n",
    "        mlflow.sklearn.log_model(clf, f\"model_{pos_group}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:24:48.517562700Z",
     "start_time": "2024-04-16T22:24:38.091546600Z"
    }
   },
   "id": "82dcf45531b86e19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "89f922e14d7da901"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
